TERRAFORM_TARGET = CONFIG.get('TERRAFORM_TARGET') or "terraform"
CONTAINER_TOOL = CONFIG.get('CONTAINER_TOOL') or "docker"

def terraform_module(
    name: str,
    srcs: list = None,
    strip: list = [],
    hashes: list = [],
    deps: list = [],
    licences: list = [],
    labels: list = [],
    visibility: list = [],
):
    """Build rule for obtaining a remote Terraform Module or defining a local Terraform module.
    Args:
        name: The name of the build rule.
        srcs: The source Terraform files for the Terraform module.
        strip: The files/directories to strip from the module.
        hashes: The hashes to verify the downloaded archive against.
        deps: The modules that this module depends on.
        licences: The licences associated with the module.
        labels: The additonal labels to add to the build rule.
        visibility: The targets to make the toolchain visible to.
    """
    module_srcs_dir=None
    module_srcs_dir=genrule(
        name = f"_{name}#srcs",
        srcs = srcs,
        outs = [f"_{name}#srcs"],
        # flatten the module as srcs in other directories should be other modules
        cmd = "mkdir $OUTS && for src in $SRCS; do cp $src $OUTS/; done",
    )

    deps=[canonicalise(dep) for dep in deps]

    # building a string to place into CMD that'll get subbed with directories
    modules_fancy = [f"$(locations {module})" for module in deps]
    modules_subbed = " ".join(modules_fancy)


    genrule(
        name = name,
        srcs = [module_srcs_dir],
        outs = [name],
        exported_deps=deps,
        deps=deps,
        visibility=visibility,
        tools=["//terraform:prepare_module"],
        cmd = f"""
$TOOLS \\
    --pkg="$PKG" \\
    --name="$NAME" \\
    --module-dir="$SRCS" \\
    --modules={modules_subbed} \\
    --out="$OUTS" \\
    --out-dir=$OUT_DIRS \\
    --strip="{strip}" \\
    --deps="{deps}"    
        """,
        env = {
            "OUT_DIRS": name,
            "TERRAFORM_TARGET": TERRAFORM_TARGET
        },
        labels=[name, "terraform_module"],
    )

def terraform_root(
    name: str,
    srcs: list,
    var_files: list = [],
    modules: list = [],
    providers: list = [],
    toolchain: str = None,
    labels: list = [],
    visibility: list = [],
    add_opinionated_workflows: bool = True,
    opt_environment: str = "development",
    environment_configs: dict = {
        "development": {
            "var-files": ["variables/development.tfvars"],
            "backend-files": ["backends/development.tfbackend"]
        },
        "production": {
            "var-files": ["variables/production.tfvars"],
            "backend-files": ["backends/production.tfbackend"]
        }
    }
):
    """Build rule for running Terraform against Terraform configuration.
    Args:
        name: The name of the build rule.
        srcs: The source Terraform files for the root module.
        vars: The Terraform var files passed into the root module.
        modules: The Terraform modules that the srcs use.
        providers: The Terraform providers that the srcs use.
        toolchain: The Terraform toolchain to use with against the srcs.
        labels: The additonal labels to add to the build rule.
        visibility: The targets to make the toolchain visible to.
        add_default_workflows: Whether or not to include the default Terraform workflows as Please targets (_plan, _apply, _destroy, _validate).
    """
    # build a Terraform root workspace
    modules=[canonicalise(module) for module in modules]

    # building a string to place into CMD that'll get subbed with directories
    modules_fancy = [f"$(locations {module})" for module in modules]
    modules_subbed = " ".join(modules_fancy)

    root=genrule(
        name = f"{name}",
        outs = [f"_{name}"],
        tools=["//terraform:prepare_workspace"],
        srcs = srcs + var_files + modules,
        data = modules,
        cmd = f"""
            $TOOLS \\
                --pkg="$PKG" \\
                --name="{name}" \\
                --os="{CONFIG.OS}" \\
                --arch="{CONFIG.ARCH}" \\
                --out="$OUTS" \\
                --pkg-dir="$PKG_DIR" \\
                --srcs="{srcs}" \\
                --var-files="{var_files}" \\
                --modules {modules_subbed}
        """,
        env = {
            "TERRAFORM_TARGET": TERRAFORM_TARGET
        },
        labels=[name, "terraform_root"],
    )


    docker_generator = genrule(
        name = f"{name}#srcs",
        outs = [f"{name}#srcs"],
        srcs = [root],
        cmd = f"""
            mkdir $OUTS && mv $SRCS $OUTS && cat << EOT > $OUTS/Dockerfile
FROM hashicorp/terraform:latest

WORKDIR /terraform

COPY _{TERRAFORM_TARGET} .
EOT""",
    )

    sh_cmd(
        name = f"{name}_container",
        shell = "/usr/bin/env bash",
        srcs = [docker_generator],
        deps = [docker_generator],
        cmd = f"""cd $(out_location {docker_generator}) && {CONTAINER_TOOL} build --no-cache -f Dockerfile .""",
        labels = ["terraform"],
    )

    if add_opinionated_workflows:
        plan_cmds = {env: generate_plan_command_for_env(root, env, environment_configs) for env in environment_configs.keys()}
        log.debug(plan_cmds)
        plan_cmds["opt"] = plan_cmds[opt_environment]

        sh_cmd(
            name = f"{name}_plan",
            shell = "/usr/bin/env bash",
            srcs = [root],
            cmd = plan_cmds,
            labels = [f"terraform_plan", "terraform"],
        )

        apply_cmds = {env: generate_apply_command_for_env(root, env, environment_configs) for env in environment_configs.keys()}
        log.debug(plan_cmds)
        apply_cmds["opt"] = apply_cmds[opt_environment]
        log.info(apply_cmds)
        sh_cmd(
            name = f"{name}_apply",
            shell = "/usr/bin/env bash",
            srcs = [root],
            cmd = apply_cmds,
            labels = [f"terraform_apply", "terraform"],
        )

        destroy_cmds = {env: generate_destroy_command_for_env(root, env, environment_configs) for env in environment_configs.keys()}
        log.debug(destroy_cmds)
        destroy_cmds["opt"] = destroy_cmds[opt_environment]
        sh_cmd(
            name = f"{name}_destroy",
            shell = "/usr/bin/env bash",
            srcs = [root],
            cmd = destroy_cmds,
            labels = [f"terraform_destroy", "terraform"],
        )

        validate_cmds = {env: generate_validate_command_for_env(root, env, environment_configs) for env in environment_configs.keys()}
        log.debug(validate_cmds)
        validate_cmds["opt"] = validate_cmds[opt_environment]
        sh_cmd(
            name = f"{name}_validate",
            shell = "/usr/bin/env bash",
            srcs = [root],
            cmd = validate_cmds,
            labels = [f"terraform_validate", "terraform"],
        )
    else:
        default_workflows = {
            "plan": "terraform init \\\$@ && terraform plan \\\$@ ",
            "apply": "terraform init \\\$@ && terraform apply \\\$@ ",
            "destroy": "terraform init \\\$@  && terraform destroy \\\$@ ",
            "validate": "terraform init -backend=false && terraform validate",
        }

        for workflow in default_workflows.keys():
            cmd = default_workflows[workflow]
            sh_cmd(
                name = f"{name}_{workflow}",
                shell = "/usr/bin/env bash",
                srcs = [root],
                # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
                # use this to allow extra parameters on the inputs
                cmd = f"cd $(out_locations {root}) && {cmd}",
                labels = [f"terraform_{workflow}", "terraform"],
            )

    return root

def get_var_file_string(env: str, environment_configs: dict):
    var_files = environment_configs.get(env).get("var-files", [])
    var_file_args = [f"--var-file {var_file}" for var_file in var_files]
    var_file_cmd_string = " ".join(var_file_args)
    return var_file_cmd_string

def get_backend_file_string(env: str, environment_configs: dict):
    backend_config_files = environment_configs.get(env).get("backend-files", [])
    backend_config_file_args = [f"--backend-config {backend_file}" for backend_file in backend_config_files]
    backend_config_cmd_string = " ".join(backend_config_file_args)
    return backend_config_cmd_string

def generate_plan_command_for_env(root: str, env: str, environment_configs: dict):
    #return {
    #    env: "" for env in environment_configs.keys()
    #}
    backend_cmd = get_backend_file_string(env, environment_configs)
    var_file_cmd = get_var_file_string(env, environment_configs)

    # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
    # use this to allow extra parameters on the inputs
    return f"cd $(out_locations {root}) && terraform init {backend_cmd} {var_file_cmd} \\\$@ && terraform plan {var_file_cmd} \\\$@",

def generate_plan_command_for_env(root: str, env: str, environment_configs: dict):
    backend_cmd = get_backend_file_string(env, environment_configs)
    var_file_cmd = get_var_file_string(env, environment_configs)

    # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
    # use this to allow extra parameters on the inputs
    return f"cd $(out_locations {root}) && terraform init {backend_cmd} {var_file_cmd} \\\$@ && terraform plan {var_file_cmd} \\\$@",

def generate_apply_command_for_env(root: str, env: str, environment_configs: dict):
    backend_cmd = get_backend_file_string(env, environment_configs)
    var_file_cmd = get_var_file_string(env, environment_configs)

    # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
    # use this to allow extra parameters on the inputs
    return f"cd $(out_locations {root}) && terraform init {backend_cmd} {var_file_cmd} \\\$@ && terraform apply {var_file_cmd} \\\$@",

def generate_destroy_command_for_env(root: str, env: str, environment_configs: dict):
    backend_cmd = get_backend_file_string(env, environment_configs)
    var_file_cmd = get_var_file_string(env, environment_configs)

    # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
    # use this to allow extra parameters on the inputs
    return f"cd $(out_locations {root}) && terraform init {backend_cmd} {var_file_cmd} \\\$@ && terraform destroy {var_file_cmd} \\\$@",

def generate_validate_command_for_env(root: str, env: str, environment_configs: dict):
    backend_cmd = get_backend_file_string(env, environment_configs)
    var_file_cmd = get_var_file_string(env, environment_configs)

    # this \\\$@ construct sufficienly escapes things to give us a real $@ behavior from shell apparently...
    # use this to allow extra parameters on the inputs
    return f"cd $(out_locations {root}) && terraform init {backend_cmd} {var_file_cmd} \\\$@ && terraform validate \\\$@",
